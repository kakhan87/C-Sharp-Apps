{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_Doner_ANN_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kakhan87/C-Sharp-Apps/blob/master/New_Doner_ANN_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgd3NM_sBz2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaGrEjzxCQQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCAzfyV1CLEi",
        "colab_type": "text"
      },
      "source": [
        "# **Part 1 - getPredictions function**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ByOgdVUNrHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPredictions():\n",
        "  '''This function takes in the user ID given by user,\n",
        "  returns a prediction of the user ID opening the email in %tage  .\n",
        "  '''\n",
        "  # Load data file\n",
        "  filename ='/content/drive/Shared drives/RA2 TechCareers Model Data/pkl_folder/base_features_ANN.pkl'\n",
        "  data = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "\n",
        "  # Loading NN model from disk\n",
        "\n",
        "  from numpy import loadtxt\n",
        "  from keras.models import load_model\n",
        "  \n",
        "  loaded_model = load_model('/content/drive/Shared drives/RA2 TechCareers Model Data/pkl_folder/New_Donor_ANN_Model.h5')\n",
        "\n",
        "  #Importing LDA data\n",
        "  %cd /content/drive/Shared drives/RA2 TechCareers Model Data/New_Donor_Prediction\n",
        "  %run 'newEmail_Topic_Modeling.ipynb' import newContentScore\n",
        "\n",
        "  #Saving column sequence of trained data\n",
        "  seq = (data.columns.values).tolist()\n",
        "\n",
        "\n",
        "  # Sorting dataset w.r.t. User IDs and email sending time\n",
        "  data_sorted = data.sort_values(['user_id', 'sent_time'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Drop dublicate User IDs and keep one with most recent email sent\n",
        "  data_dropped = data_sorted.drop_duplicates(subset='user_id', keep='first', inplace=False)\n",
        "\n",
        "\n",
        "  #Shift data\n",
        "  data_shifted = data_dropped.drop(['Opened_L5'], axis=1)\n",
        "  data_shifted = data_shifted.rename(columns={'Opened_L4': 'Opened_L5', \n",
        "                                              'Opened_L3': 'Opened_L4', \n",
        "                                              'Opened_L2': 'Opened_L3', \n",
        "                                              'Opened_L1': 'Opened_L2', \n",
        "                                              'opened': 'Opened_L1'})\n",
        "\n",
        "  data_shifted = data_dropped.drop(['T4_L5', 'T3_L5', 'T2_L5', 'T1_L5', 'T0_L5'], axis=1)\n",
        "\n",
        "  for i in range (4,-1,-1):\n",
        "    for j in range (5,0,-1):\n",
        "      new_name = ('T'+str(i)+'_L'+str(j-1))\n",
        "      old_name = ('T'+str(i)+'_L'+str(j))\n",
        "      data_shifted = data_shifted.rename(columns={new_name:old_name})\n",
        "    new_name = ('content_topic_'+str(i))\n",
        "    data_shifted = data_shifted.rename(columns={new_name:old_name})\n",
        "\n",
        "\n",
        "  #Initializing prediction list for user IDs\n",
        "  user_pred = []\n",
        "  #Getting list of user IDs to make predictions\n",
        "  user_list = data['user_id'].to_numpy().tolist()\n",
        "  # user_list = [5545, 13658, 18215]\n",
        "  #Looping over each user to make preidctions\n",
        "  for user in user_list:\n",
        "\n",
        "    # Creating dataframe for one single user at a time\n",
        "    # data_input = data_shifted.loc[data_shifted['user_id'].isin(user)]\n",
        "    data_input = data_shifted[data_shifted['user_id'] == user]\n",
        "\n",
        "    #Adding user ID to new content score\n",
        "    newScore = newContentScore.assign(user_id = [user]) \n",
        "\n",
        "    #Merging Content topic \n",
        "    data_joined = pd.merge(data_input, newScore, on='user_id', how='inner')\n",
        "\n",
        "    #Dropping user ID from new content score\n",
        "    newScore = newScore.drop(['user_id'], 1)\n",
        "\n",
        "    #Arranging column\n",
        "    data_ordered = data_joined.reindex(columns=seq)\n",
        "\n",
        "\n",
        "\n",
        "    #Dropping unnecessary columns from new user data\n",
        "    X_test = data_ordered.drop(['email_id', 'user_id', 'sent_time', 'opened'], 1)\n",
        "\n",
        "\n",
        "    # Making the predictions\n",
        "    y_pred = np.array(loaded_model.predict(X_test))[0][0].tolist()\n",
        "    user_pred.append(y_pred)  \n",
        "\n",
        "  print(user_pred)\n",
        "  def user_pred_histogram (y_pred_list, user_list):\n",
        "\n",
        "    data_plot = pd.DataFrame({\"Prediction\":y_pred_list, \"User_List\":user_list})\n",
        "    data_plot.set_index('User_List', inplace=True)\n",
        "\n",
        "    # np.histogram returns 2 values\n",
        "    count, bin_edges = np.histogram(data_plot)\n",
        "    bin_edges = np.round(bin_edges,2) # Round bin_edges to 1 decimal place \n",
        "    # print(\"Frequency Count:\", count) # frequency count\n",
        "    # print(\"Bins:\", bin_edges) # bin ranges, default = 10 bins\n",
        "\n",
        "    # Density Plot and Histogram of all arrival delays\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.distplot(data_plot, hist=True, kde=False, \n",
        "                bins=bin_edges, color = 'darkblue', \n",
        "                hist_kws={'edgecolor':'black'})\n",
        "\n",
        "    plt.title('Histogram of Predicted Number of Users Opening a New E-mail') # add a title to the histogram\n",
        "    plt.ylabel('Number of Users') # add y-label\n",
        "    plt.xlabel('Likelihood of Opening New E-mail') # add x-label\n",
        "\n",
        "    plt.rcParams.update({'font.size': 18})\n",
        "    plt.show()\n",
        "\n",
        "  user_pred_histogram(user_pred, user_list)\n",
        "\n",
        "  # return user_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCw3tdBAXj7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getPredictions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZMc4ew0X5qF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}